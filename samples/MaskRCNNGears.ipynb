{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaskRCNNGears.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xfOVvHQaNv5C",
        "Do6Xyz_jMcuj",
        "fFIGa95vQseU",
        "ufyLWNiHQzh0",
        "noXP8Hx4RGlb",
        "ekMFwse5LaUP"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjJiwFoSKO_d",
        "colab_type": "text"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LYt3XK-NzYw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   You labled your images with the VGG Image Annotator (VIA) and only used polygons\n",
        "2.   You saved the training images and the json file for the training images in data/train (same for the validation set)\n",
        "3.   You adjusted the load_balloon method in the balloon python file (see the ppt presentation)\n",
        "4.   If you want to continue training a network, you loaded it in a appropriate directory as a hdf5 file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xfOVvHQaNv5C"
      },
      "source": [
        "# Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "af301e7c-87df-403e-87f6-7c5b84945030",
        "id": "y9DWDGQ-Nv5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/Eoli-an/Mask_RCNN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 1108, done.\u001b[K\n",
            "remote: Total 1108 (delta 0), reused 0 (delta 0), pack-reused 1108\u001b[K\n",
            "Receiving objects: 100% (1108/1108), 123.19 MiB | 37.19 MiB/s, done.\n",
            "Resolving deltas: 100% (626/626), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q6WdW0isNv5W"
      },
      "source": [
        "This code is used to create the repository in which the trained neural net will be safed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y1CVazw8Nv5X",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "os.chdir(\"./Mask_RCNN/data/gear\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do6Xyz_jMcuj",
        "colab_type": "text"
      },
      "source": [
        "# Confirm that you use the GPU\n",
        "click on \"runtime\" -> \"change runtime type\" -> choose \"GPU\" on the accelerator field. (The free GPU is why we use colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_EUh2eJMxsU",
        "colab_type": "code",
        "outputId": "cb95dcb4-72e5-4025-fe87-23d3d23bc463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFIGa95vQseU",
        "colab_type": "text"
      },
      "source": [
        "# Manage imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySO-ukihF3__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import itertools\n",
        "import math\n",
        "import logging\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.lines as lines\n",
        "from matplotlib.patches import Polygon\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "from samples.balloon import balloon\n",
        "\n",
        "%matplotlib inline\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnxwvvICQweU",
        "colab_type": "text"
      },
      "source": [
        "Config of paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6adq07i1V5H9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "config = balloon.BalloonConfig()\n",
        "BALLOON_DIR = os.path.join(ROOT_DIR, \"data/gear\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufyLWNiHQzh0",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OisftMvUaYeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "# Get the dataset from the releases page\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "dataset = balloon.BalloonDataset()\n",
        "dataset.load_balloon(BALLOON_DIR, \"train\")\n",
        "\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset.num_classes))\n",
        "for i, info in enumerate(dataset.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noXP8Hx4RGlb",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the Training images\n",
        "This Section is used to validate that everything is fine with the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBOLD3KlQ8-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask, class_ids = dataset.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr_8dmsGRbDk",
        "colab_type": "text"
      },
      "source": [
        "visualize image boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RSVJWHmRR_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Load random image and mask.\n",
        "image_id = random.choice(dataset.image_ids)\n",
        "image = dataset.load_image(image_id)\n",
        "mask, class_ids = dataset.load_mask(image_id)\n",
        "# Compute Bounding box\n",
        "bbox = utils.extract_bboxes(mask)\n",
        "\n",
        "# Display image and additional stats\n",
        "print(\"image_id \", image_id, dataset.image_reference(image_id))\n",
        "log(\"image\", image)\n",
        "log(\"mask\", mask)\n",
        "log(\"class_ids\", class_ids)\n",
        "log(\"bbox\", bbox)\n",
        "# Display image and instances\n",
        "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPkqypt5W1iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_id = np.random.choice(dataset.image_ids, 1)[0]\n",
        "image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
        "    dataset, config, image_id, use_mini_mask=False)\n",
        "\n",
        "log(\"image\", image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"class_ids\", class_ids)\n",
        "log(\"bbox\", bbox)\n",
        "log(\"mask\", mask)\n",
        "\n",
        "display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71rbd8M3XGHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIhlej9zXJcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add augmentation and mask resizing.\n",
        "image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
        "    dataset, config, image_id, augment=True, use_mini_mask=True)\n",
        "log(\"mask\", mask)\n",
        "display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekMFwse5LaUP",
        "colab_type": "text"
      },
      "source": [
        "# Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90vnCruCYimV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "os.chdir(\"..\")\n",
        "os.chdir(\"..\")\n",
        "os.chdir(\"./samples/balloon\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TteSpF8ELeBf",
        "colab_type": "text"
      },
      "source": [
        "If you have trained the neural net before and want to continue training, change coco to last"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdNIZS59YXcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 balloon.py train --dataset=/content/Mask_RCNN/data/gear --weights=coco"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezbTLANWLpEn",
        "colab_type": "text"
      },
      "source": [
        "The trained network will be safed somewhere in the logs directory.\n",
        "You can browse the directories by clicking on \"files\" at the left hand side of this website.\n",
        "After you close your browser your runtime will be disconnected. This implies that all the files you created will be lost. So if you want to keep the trained neural net you will have to download the hdf5 file(right click and download in the file manager)"
      ]
    }
  ]
}